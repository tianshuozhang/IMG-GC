{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-17T03:01:32.140488500Z",
     "start_time": "2024-03-17T03:01:28.777759900Z"
    }
   },
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionImg2ImgPipeline\n",
    "from get_input import get_img\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-17T03:02:12.460164500Z",
     "start_time": "2024-03-17T03:02:06.421470600Z"
    }
   },
   "outputs": [],
   "source": [
    "# model_path=r\"C:\\Users\\17612\\Desktop\\course-management\\AIGC\\img2img\"\n",
    "model_path = r\"D:\\model\\img2img\"\n",
    "pipe = StableDiffusionImg2ImgPipeline.from_pretrained(model_path,torch_dtype=torch.float16,revision=\"fp16\",use_auth_token=True)\n",
    "# pipe = StableDiffusionImg2ImgPipeline.from_pretrained(model_path,use_auth_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe=pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-17T03:03:59.469376200Z",
     "start_time": "2024-03-17T03:02:58.185065300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e5cb6c7977a947ac9b3957f3f21a6c91"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 46457856000 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m url\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../.jpg\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      5\u001B[0m raw_image\u001B[38;5;241m=\u001B[39mget_img(url\u001B[38;5;241m=\u001B[39murl,local_img\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m----> 6\u001B[0m image \u001B[38;5;241m=\u001B[39m \u001B[43mpipe\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mraw_image\u001B[49m\u001B[43m,\u001B[49m\u001B[43mprompt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43mstrength\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.75\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mguidance_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m7.5\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mimages[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AIGC\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001B[0m, in \u001B[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     26\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclone():\n\u001B[1;32m---> 27\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AIGC\\lib\\site-packages\\diffusers\\pipelines\\stable_diffusion\\pipeline_stable_diffusion_img2img.py:720\u001B[0m, in \u001B[0;36mStableDiffusionImg2ImgPipeline.__call__\u001B[1;34m(self, prompt, image, strength, num_inference_steps, guidance_scale, negative_prompt, num_images_per_prompt, eta, generator, prompt_embeds, negative_prompt_embeds, output_type, return_dict, callback, callback_steps, cross_attention_kwargs)\u001B[0m\n\u001B[0;32m    717\u001B[0m latent_model_input \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscheduler\u001B[38;5;241m.\u001B[39mscale_model_input(latent_model_input, t)\n\u001B[0;32m    719\u001B[0m \u001B[38;5;66;03m# predict the noise residual\u001B[39;00m\n\u001B[1;32m--> 720\u001B[0m noise_pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munet\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    721\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlatent_model_input\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    722\u001B[0m \u001B[43m    \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    723\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprompt_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    724\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcross_attention_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcross_attention_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    725\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39msample\n\u001B[0;32m    727\u001B[0m \u001B[38;5;66;03m# perform guidance\u001B[39;00m\n\u001B[0;32m    728\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m do_classifier_free_guidance:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AIGC\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AIGC\\lib\\site-packages\\diffusers\\models\\unet_2d_condition.py:724\u001B[0m, in \u001B[0;36mUNet2DConditionModel.forward\u001B[1;34m(self, sample, timestep, encoder_hidden_states, class_labels, timestep_cond, attention_mask, cross_attention_kwargs, down_block_additional_residuals, mid_block_additional_residual, return_dict)\u001B[0m\n\u001B[0;32m    722\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m downsample_block \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdown_blocks:\n\u001B[0;32m    723\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(downsample_block, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_cross_attention\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m downsample_block\u001B[38;5;241m.\u001B[39mhas_cross_attention:\n\u001B[1;32m--> 724\u001B[0m         sample, res_samples \u001B[38;5;241m=\u001B[39m \u001B[43mdownsample_block\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    725\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    726\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtemb\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43memb\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    727\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    728\u001B[0m \u001B[43m            \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    729\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcross_attention_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcross_attention_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    730\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    731\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    732\u001B[0m         sample, res_samples \u001B[38;5;241m=\u001B[39m downsample_block(hidden_states\u001B[38;5;241m=\u001B[39msample, temb\u001B[38;5;241m=\u001B[39memb)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AIGC\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AIGC\\lib\\site-packages\\diffusers\\models\\unet_2d_blocks.py:867\u001B[0m, in \u001B[0;36mCrossAttnDownBlock2D.forward\u001B[1;34m(self, hidden_states, temb, encoder_hidden_states, attention_mask, cross_attention_kwargs)\u001B[0m\n\u001B[0;32m    865\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    866\u001B[0m         hidden_states \u001B[38;5;241m=\u001B[39m resnet(hidden_states, temb)\n\u001B[1;32m--> 867\u001B[0m         hidden_states \u001B[38;5;241m=\u001B[39m \u001B[43mattn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    868\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    869\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    870\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcross_attention_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcross_attention_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    871\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39msample\n\u001B[0;32m    873\u001B[0m     output_states \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (hidden_states,)\n\u001B[0;32m    875\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdownsamplers \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AIGC\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AIGC\\lib\\site-packages\\diffusers\\models\\transformer_2d.py:265\u001B[0m, in \u001B[0;36mTransformer2DModel.forward\u001B[1;34m(self, hidden_states, encoder_hidden_states, timestep, class_labels, cross_attention_kwargs, return_dict)\u001B[0m\n\u001B[0;32m    263\u001B[0m \u001B[38;5;66;03m# 2. Blocks\u001B[39;00m\n\u001B[0;32m    264\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m block \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransformer_blocks:\n\u001B[1;32m--> 265\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[43mblock\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    266\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    267\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    268\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimestep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimestep\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    269\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcross_attention_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcross_attention_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    270\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclass_labels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclass_labels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    271\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    273\u001B[0m \u001B[38;5;66;03m# 3. Output\u001B[39;00m\n\u001B[0;32m    274\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_input_continuous:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AIGC\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AIGC\\lib\\site-packages\\diffusers\\models\\attention.py:313\u001B[0m, in \u001B[0;36mBasicTransformerBlock.forward\u001B[1;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, timestep, cross_attention_kwargs, class_labels)\u001B[0m\n\u001B[0;32m    310\u001B[0m     norm_hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm1(hidden_states)\n\u001B[0;32m    312\u001B[0m cross_attention_kwargs \u001B[38;5;241m=\u001B[39m cross_attention_kwargs \u001B[38;5;28;01mif\u001B[39;00m cross_attention_kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m {}\n\u001B[1;32m--> 313\u001B[0m attn_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mattn1(\n\u001B[0;32m    314\u001B[0m     norm_hidden_states,\n\u001B[0;32m    315\u001B[0m     encoder_hidden_states\u001B[38;5;241m=\u001B[39mencoder_hidden_states \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39monly_cross_attention \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    316\u001B[0m     attention_mask\u001B[38;5;241m=\u001B[39mattention_mask,\n\u001B[0;32m    317\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcross_attention_kwargs,\n\u001B[0;32m    318\u001B[0m )\n\u001B[0;32m    319\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muse_ada_layer_norm_zero:\n\u001B[0;32m    320\u001B[0m     attn_output \u001B[38;5;241m=\u001B[39m gate_msa\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m*\u001B[39m attn_output\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AIGC\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AIGC\\lib\\site-packages\\diffusers\\models\\attention_processor.py:267\u001B[0m, in \u001B[0;36mAttention.forward\u001B[1;34m(self, hidden_states, encoder_hidden_states, attention_mask, **cross_attention_kwargs)\u001B[0m\n\u001B[0;32m    263\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, hidden_states, encoder_hidden_states\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, attention_mask\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcross_attention_kwargs):\n\u001B[0;32m    264\u001B[0m     \u001B[38;5;66;03m# The `Attention` class can call different attention processors / attention functions\u001B[39;00m\n\u001B[0;32m    265\u001B[0m     \u001B[38;5;66;03m# here we simply pass along all tensors to the selected processor class\u001B[39;00m\n\u001B[0;32m    266\u001B[0m     \u001B[38;5;66;03m# For standard processors that are defined here, `**cross_attention_kwargs` is empty\u001B[39;00m\n\u001B[1;32m--> 267\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocessor(\n\u001B[0;32m    268\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    269\u001B[0m         hidden_states,\n\u001B[0;32m    270\u001B[0m         encoder_hidden_states\u001B[38;5;241m=\u001B[39mencoder_hidden_states,\n\u001B[0;32m    271\u001B[0m         attention_mask\u001B[38;5;241m=\u001B[39mattention_mask,\n\u001B[0;32m    272\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcross_attention_kwargs,\n\u001B[0;32m    273\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AIGC\\lib\\site-packages\\diffusers\\models\\attention_processor.py:406\u001B[0m, in \u001B[0;36mAttnProcessor.__call__\u001B[1;34m(self, attn, hidden_states, encoder_hidden_states, attention_mask)\u001B[0m\n\u001B[0;32m    403\u001B[0m key \u001B[38;5;241m=\u001B[39m attn\u001B[38;5;241m.\u001B[39mhead_to_batch_dim(key)\n\u001B[0;32m    404\u001B[0m value \u001B[38;5;241m=\u001B[39m attn\u001B[38;5;241m.\u001B[39mhead_to_batch_dim(value)\n\u001B[1;32m--> 406\u001B[0m attention_probs \u001B[38;5;241m=\u001B[39m \u001B[43mattn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_attention_scores\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    407\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mbmm(attention_probs, value)\n\u001B[0;32m    408\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m attn\u001B[38;5;241m.\u001B[39mbatch_to_head_dim(hidden_states)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AIGC\\lib\\site-packages\\diffusers\\models\\attention_processor.py:300\u001B[0m, in \u001B[0;36mAttention.get_attention_scores\u001B[1;34m(self, query, key, attention_mask)\u001B[0m\n\u001B[0;32m    297\u001B[0m     key \u001B[38;5;241m=\u001B[39m key\u001B[38;5;241m.\u001B[39mfloat()\n\u001B[0;32m    299\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m attention_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 300\u001B[0m     baddbmm_input \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mempty\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    301\u001B[0m \u001B[43m        \u001B[49m\u001B[43mquery\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquery\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquery\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquery\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\n\u001B[0;32m    302\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    303\u001B[0m     beta \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m    304\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[1;31mRuntimeError\u001B[0m: [enforce fail at ..\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 46457856000 bytes."
     ]
    }
   ],
   "source": [
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "text=\"The two people in the picture maintain the same pose while changing the background to a desert.\"\n",
    "# text=\"Generate a picture in which three dogs run\"\n",
    "url=\"../.jpg\"\n",
    "raw_image=get_img(url=url,local_img=True)\n",
    "image = pipe(image=raw_image,prompt=text,strength=0.75, guidance_scale=7.5).images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIGC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
